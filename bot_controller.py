import json
import os
import asyncio
import logging
import time
import hashlib
import PIL
import aiofiles
import aiohttp
import re
import concurrent.futures
import psutil
from datetime import datetime, timedelta
from datetime import time as time_class
from typing import Dict, List, Optional, Tuple, Any, Union
from urllib.parse import urlparse
from PIL import Image
from functools import lru_cache
from bs4 import BeautifulSoup
import pytz
from telegram import CallbackQuery
from rss_parser import AsyncRSSParser
from state_manager import StateManager

logger = logging.getLogger('bot.controller')

class BotController:
    def __init__(self, config, state_manager, rss_parser, image_generator, yandex_gpt, telegram_bot):
        self.config = config
        self.state_manager = state_manager
        self.rss_parser = rss_parser
        self.image_generator = image_generator
        self.yandex_gpt = yandex_gpt
        self.telegram_bot = telegram_bot
        self.REQUIRE_IMAGE = True
        self._validate_config()
        self.hourly_stats = {f"hour_{h}": 0 for h in range(24)}

        self.publication_mode = config.PUBLICATION_MODE
        self.min_delay = config.MIN_DELAY_BETWEEN_POSTS
        self.publication_schedule = config.PUBLICATION_SCHEDULE
        self.next_scheduled_time = None
        self.schedule_changed = asyncio.Event()
        
        if self.publication_mode == 'schedule':
            self._calculate_next_scheduled_time()
        
        logger.info(f"–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: mode={self.publication_mode}, delay={self.min_delay}s, schedule={self.publication_schedule}")
        
        self.logger = logging.getLogger('bot.controller')
        self.session = None
        self.image_semaphore = None
        self.is_running = False
        self.cleanup_task = None
        self.rss_task = None
        self.session_refresh_task = None
        self.task_monitor_task = None
        self.last_post_time = 0.0
        
        self.image_executor = concurrent.futures.ProcessPoolExecutor(
            max_workers=config.IMAGE_GENERATION_WORKERS
        )
        
        self.stats = {
            'start_time': datetime.now(),
            'posts_sent': 0,
            'last_check': None,
            'errors': 0,
            'last_post': None,
            'yagpt_used': 0,
            'yagpt_errors': 0,
            'image_errors': 0,
            'images_generated': 0,
            'images_deleted': 0,
            'storage_freed': 0.0,
            'last_cleanup': None,
            'cycles_completed': 0,
            'avg_processing_time': 0.0,
            'total_processing_time': 0.0,
            'max_feed_time': 0.0,
            'min_feed_time': float('inf'),
            'last_cleanup_result': "",
            'duplicates_rejected': 0
        }
        
        self.post_timestamps = []
        
        try:
            state_file_exists = os.path.exists(self.state_manager.state_file)
            self.state_manager.load_state()
            
            if not state_file_exists:
                self.logger.warning(f"State file {self.state_manager.state_file} not found, creating new one")
                try:
                    self.state_manager.save_state()
                    self.logger.info(f"New state file created: {self.state_manager.state_file}")
                except Exception as e:
                    self.logger.error(f"Failed to create state file: {str(e)}")
            
            if 'stats' in self.state_manager.state:
                self.stats.update(self.state_manager.state['stats'])
                self.logger.debug("Stats loaded from state")
        except Exception as e:
            self.logger.error(f"Error initializing state: {str(e)}", exc_info=True)
            try:
                self.state_manager.save_state()
                self.logger.warning("Created backup state after initialization error")
            except Exception as backup_error:
                self.logger.critical(f"Critical state error: {str(backup_error)}")
        
        # –î–æ–±–∞–≤–ª–µ–Ω–æ: —Å–æ–±—ã—Ç–∏–µ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–∏
        self.schedule_changed = asyncio.Event()
    
    def _validate_config(self):
        required = [
            'TOKEN', 
            'CHANNEL_ID',
            'RSS_URLS',
            'MAX_IMAGE_WIDTH',
            'MAX_IMAGE_HEIGHT'
        ]
        for param in required:
            if not hasattr(self.config, param) or not getattr(self.config, param):
                raise ValueError(f"Missing required config: {param}")
            
    def is_available(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –¥–æ—Å—Ç—É–ø–µ–Ω –ª–∏ —Å–µ—Ä–≤–∏—Å Yandex GPT"""
        return (self.config.YANDEX_API_KEY and 
                self.config.YANDEX_FOLDER_ID and 
                self.config.YANDEX_API_ENDPOINT and
                self.active)

    async def _create_session(self) -> aiohttp.ClientSession:
        """–°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—É—é aiohttp —Å–µ—Å—Å–∏—é"""
        return aiohttp.ClientSession(
            connector=aiohttp.TCPConnector(
                force_close=True,
                enable_cleanup_closed=True,
                limit=0
            ),
            timeout=aiohttp.ClientTimeout(total=30)
        )
    
    async def _recreate_session(self):
        """–ü–µ—Ä–µ—Å–æ–∑–¥–∞–µ—Ç HTTP-—Å–µ—Å—Å–∏—é –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏"""
        logger.critical("Recreating HTTP session due to closed state...")
        try:
            if self.session:
                await self.session.close()
            self.session = await self._create_session()
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–µ—Å—Å–∏–∏ –≤–æ –≤—Å–µ—Ö –∑–∞–≤–∏—Å–∏–º—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞—Ö
            self.rss_parser.session = self.session
            if self.yandex_gpt:
                self.yandex_gpt.session = self.session
                
            logger.info("HTTP session recreated successfully")
        except Exception as e:
            logger.error(f"Session recreation failed: {str(e)}")

    async def start(self) -> bool:
        """–ó–∞–ø—É—Å–∫ –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –±–æ—Ç–∞"""
        if self.is_running:
            logger.warning("Controller is already running")
            return False
            
        # –î–æ–±–∞–≤–ª–µ–Ω–æ: –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —É–∂–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏
        if hasattr(self, '_tasks_initialized'):
            delattr(self, '_tasks_initialized')
            logger.warning("Tasks already initialized")
            return False
            
        try:
            self.session = await self._create_session()
            self.image_semaphore = asyncio.Semaphore(self.config.MAX_CONCURRENT_IMAGE_TASKS)
            self.is_running = True
            self.last_post_time = time.time()
            
            logger.info("Starting controller with %d RSS feeds", len(self.config.RSS_URLS))
            
            # –ó–∞–ø—É—Å–∫ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∑–∞–¥–∞—á
            self.rss_task = asyncio.create_task(self._rss_processing_loop())
            self.cleanup_task = asyncio.create_task(self._cleanup_loop())
            self.session_refresh_task = asyncio.create_task(self._session_refresh_loop())
            self.task_monitor_task = asyncio.create_task(self._task_monitor_loop())
            
            # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–∞—Ä—Å–µ—Ä–∞ RSS —Å –∫–æ–ª–±—ç–∫–æ–º –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏—è —Å–µ—Å—Å–∏–∏
            self.rss_parser = AsyncRSSParser(
                session=self.session,
                proxy_url=self.config.PROXY_URL,
                on_session_recreate=self._recreate_session
            )
            
            # –ü–æ–º–µ—á–∞–µ–º –∑–∞–¥–∞—á–∏ –∫–∞–∫ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ
            self._tasks_initialized = True
            return True
        except Exception as e:
            logger.error("Failed to start controller: %s", str(e), exc_info=True)
            await self._safe_shutdown()
            return False

    async def stop(self) -> bool:
        """–ö–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–æ—Ç–∞"""
        if not self.is_running:
            logger.warning("Controller is not running")
            return False
            
        logger.info("Stopping controller...")
        self.is_running = False
        
        try:
            # –û—Ç–º–µ–Ω–∞ –≤—Å–µ—Ö –∑–∞–¥–∞—á
            tasks = []
            if self.rss_task and not self.rss_task.done():
                self.rss_task.cancel()
                tasks.append(self.rss_task)
            if self.cleanup_task and not self.cleanup_task.done():
                self.cleanup_task.cancel()
                tasks.append(self.cleanup_task)
            if self.session_refresh_task and not self.session_refresh_task.done():
                self.session_refresh_task.cancel()
                tasks.append(self.session_refresh_task)
            if self.task_monitor_task and not self.task_monitor_task.done():
                self.task_monitor_task.cancel()
                tasks.append(self.task_monitor_task)
            
            if tasks:
                await asyncio.gather(*tasks, return_exceptions=True)
            
            if hasattr(self, '_tasks_initialized'):
                delattr(self, '_tasks_initialized')  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥
            
            # –ó–∞–∫—Ä—ã—Ç–∏–µ —Å–µ—Å—Å–∏–∏ –∏ –æ—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤
            await self._safe_shutdown()
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
            self.state_manager.save_state()
            
            logger.info("Controller stopped successfully")
            return True
        except Exception as e:
            logger.error("Error during shutdown: %s", str(e), exc_info=True)
            return False

    async def _safe_shutdown(self):
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        if self.session and not self.session.closed:
            await self.session.close()
        if hasattr(self.image_generator, 'shutdown'):
            self.image_generator.shutdown()
        if self.image_executor:
            self.image_executor.shutdown(wait=False)

    async def _session_refresh_loop(self):
        """–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ HTTP-—Å–µ—Å—Å–∏–∏"""
        logger.info("Starting session refresh loop")
        while self.is_running:
            try:
                await asyncio.sleep(3600)  # –ö–∞–∂–¥—ã–π —á–∞—Å
                
                if self.session:
                    logger.info("Refreshing HTTP session...")
                    await self.session.close()
                    self.session = await self._create_session()
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å–µ—Å—Å–∏–∏ –≤ –∑–∞–≤–∏—Å–∏–º—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞—Ö
                    self.rss_parser.session = self.session
                    if self.yandex_gpt:
                        self.yandex_gpt.session = self.session
                        
                    logger.info("HTTP session refreshed successfully")
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Session refresh failed: {str(e)}")
                # –ü–æ–≤—Ç–æ—Ä–∏—Ç—å —á–µ—Ä–µ–∑ 5 –º–∏–Ω—É—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ
                await asyncio.sleep(300)

    async def _task_monitor_loop(self):
        """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –æ—á–∏—Å—Ç–∫–∞ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á"""
        logger.info("Starting task monitor loop")
        max_tasks = 500  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á
        while self.is_running:
            try:
                await asyncio.sleep(300)  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç
                await self._cleanup_tasks(max_tasks)
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Task monitor error: {str(e)}")

    async def _cleanup_tasks(self, max_tasks: int):
        """–û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö –∏ —Å—Ç–∞—Ä—ã—Ö –∑–∞–¥–∞—á"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ç–µ–∫—É—â–∏–µ –∑–∞–¥–∞—á–∏, –∫—Ä–æ–º–µ —Ç–µ–∫—É—â–µ–π
            current_tasks = [t for t in asyncio.all_tasks() if t is not asyncio.current_task()]
            task_count = len(current_tasks)
            
            if task_count <= max_tasks:
                return
                
            logger.warning(f"High task count: {task_count}/{max_tasks}, performing cleanup...")
            
            # –°–æ–±–∏—Ä–∞–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏
            finished_tasks = [t for t in current_tasks if t.done()]
            
            # –°–æ–±–∏—Ä–∞–µ–º —Å–∞–º—ã–µ —Å—Ç–∞—Ä—ã–µ –∞–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏ –¥–ª—è –æ—Ç–º–µ–Ω—ã
            tasks_to_cancel = sorted(
                [t for t in current_tasks if not t.done()],
                key=lambda t: t.get_name() if hasattr(t, 'get_name') else str(t),
                reverse=True
            )[:max(0, task_count - max_tasks)]
            
            # –û—Ç–º–µ–Ω—è–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏
            for task in tasks_to_cancel:
                if not task.done():
                    task.cancel()
            
            # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ—Ç–º–µ–Ω–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
            await asyncio.gather(*tasks_to_cancel, return_exceptions=True)
            
            logger.info(f"Cleaned up {len(finished_tasks)} finished and {len(tasks_to_cancel)} old tasks")
        except Exception as e:
            logger.error(f"Task cleanup failed: {str(e)}")

    def refresh_schedule(self) -> None:
        """–ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ—Ç –≤—Ä–µ–º—è —Å–ª–µ–¥—É—é—â–µ–π –ø—É–±–ª–∏–∫–∞—Ü–∏–∏"""
        if self.publication_mode == 'schedule':
            tz = pytz.timezone(self.config.TIMEZONE)
            self._calculate_next_scheduled_time()
            logger.info(f"–°–ª–µ–¥—É—é—â–∞—è –ø—É–±–ª–∏–∫–∞—Ü–∏—è: {self.next_scheduled_time.astimezone(tz).strftime('%Y-%m-%d %H:%M')}")

    def _calculate_next_scheduled_time(self):
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å–ª–µ–¥—É—é—â–µ–µ –≤—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ —Å —É—á–µ—Ç–æ–º —á–∞—Å–æ–≤–æ–≥–æ –ø–æ—è—Å–∞"""
        tz = pytz.timezone(self.config.TIMEZONE)
        now = datetime.now(tz)
        current_time = now.time()
        
        # –ó–∞—â–∏—Ç–∞ –æ—Ç –ø—É—Å—Ç–æ–≥–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è
        if not self.publication_schedule:
            logger.warning("Publication schedule is empty! Using default.")
            self.publication_schedule = [time(9, 0), time(12, 0), time(18, 0)]
        
        # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
        all_candidates = []
        
        # –°–µ–≥–æ–¥–Ω—è—à–Ω–∏–µ —Å–ª–æ—Ç—ã
        for t in self.publication_schedule:
            candidate = datetime.combine(now.date(), t)
            candidate = tz.localize(candidate)
            if candidate > now:  # —Ç–æ–ª—å–∫–æ –±—É–¥—É—â–∏–µ —Å–ª–æ—Ç—ã
                all_candidates.append(candidate)
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Å–ª–æ—Ç—ã —Å–µ–≥–æ–¥–Ω—è - –±–µ—Ä–µ–º –±–ª–∏–∂–∞–π—à–∏–π
        if all_candidates:
            next_time_candidate = min(all_candidates)
        else:
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Å–ª–æ—Ç –∑–∞–≤—Ç—Ä–∞
            tomorrow = now + timedelta(days=1)
            next_time = self.publication_schedule[0]
            next_time_candidate = tz.localize(datetime.combine(tomorrow.date(), next_time))
        
        self.next_scheduled_time = next_time_candidate
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤–æ–µ –≤—Ä–µ–º—è
        wait_seconds = (self.next_scheduled_time - now).total_seconds()
        logger.info(f"–°–ª–µ–¥—É—é—â–∞—è –ø—É–±–ª–∏–∫–∞—Ü–∏—è: {self.next_scheduled_time.strftime('%Y-%m-%d %H:%M:%S')}")
        #logger.info(f"–û–∂–∏–¥–∞–Ω–∏–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: {wait_seconds:.1f} —Å–µ–∫ ({wait_seconds/60:.1f} –º–∏–Ω)")

    # –î–æ–±–∞–≤—å—Ç–µ —ç—Ç–∏ –º–µ—Ç–æ–¥—ã –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏:
    def set_publication_mode(self, mode):
        self.publication_mode = mode
        if mode == 'schedule':
            self._calculate_next_scheduled_time()
        logger.info(f"–†–µ–∂–∏–º –∏–∑–º–µ–Ω–µ–Ω –Ω–∞ '{mode}'")

    def set_publication_schedule(self, times):
        self.publication_schedule = sorted(times)
        if self.publication_mode == 'schedule':
            self._calculate_next_scheduled_time()
        logger.info(f"–ù–æ–≤–æ–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ: {[t.strftime('%H:%M') for t in times]}")
    
    def set_publication_mode(self, mode: str):
        self.publication_mode = mode
        if mode == 'schedule':
            self._calculate_next_scheduled_time()

    def set_publication_schedule(self, times: List[time_class]):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –Ω–æ–≤–æ–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–π"""
        self.publication_schedule = sorted(times)
        
        # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø–µ—Ä–µ—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏
        self._calculate_next_scheduled_time()
        
        # –°–∏–≥–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–± –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è
        self.schedule_changed.set()
        logger.info(f"–†–∞—Å–ø–∏—Å–∞–Ω–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–æ: {[t.strftime('%H:%M') for t in times]}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–æ–Ω—Ñ–∏–≥
        schedule_str = ','.join([t.strftime('%H:%M') for t in self.publication_schedule])
        self.config.PUBLICATION_SCHEDULE = schedule_str
        self.config.save_to_env_file("PUBLICATION_SCHEDULE", schedule_str)

    async def _rss_processing_loop(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ RSS-–ª–µ–Ω—Ç"""
        last_save_time = time.time()
        
        while self.is_running:
            cycle_start = time.time()
            try:
                self.stats['last_check'] = datetime.now()
                
                # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–≤—ã—Ö –ø–æ—Å—Ç–æ–≤
                new_posts = await self._fetch_all_feeds()
                if new_posts:
                    await self._process_new_posts(new_posts)
                # –ï—Å–ª–∏ –ø–æ—Å—Ç–æ–≤ –Ω–µ—Ç, –Ω–æ —Ä–µ–∂–∏–º —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è - –∂–¥–µ–º –≤—Ä–µ–º–µ–Ω–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
                elif self.publication_mode == 'schedule':
                    await self._wait_for_publication_time()
                
                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                cycle_time = time.time() - cycle_start
                self._update_processing_stats(cycle_time)
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç
                if time.time() - last_save_time > 300:
                    self.state_manager.save_state()
                    last_save_time = time.time()
                    
                await asyncio.sleep(self.config.CHECK_INTERVAL)
                
            except asyncio.CancelledError:
                logger.info("RSS processing loop cancelled")
                break
            except Exception as e:
                logger.error("Error in RSS processing loop: %s", str(e), exc_info=True)
                await asyncio.sleep(min(60, self.config.CHECK_INTERVAL * 2))

    async def _fetch_all_feeds(self) -> List[Dict]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ RSS-–ª–µ–Ω—Ç —Å –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        new_posts = []
        if not self.is_running:
            return new_posts
            
        logger.info("‚è≥ –ù–∞—á–∞–ª–æ –∑–∞–≥—Ä—É–∑–∫–∏ RSS-–ª–µ–Ω—Ç")
        active_feeds = 0
        total_new = 0
        
        for i, url in enumerate(self.config.RSS_URLS):
            try:
                if not self.is_running:
                    break
                    
                # –ü—Ä–æ–ø—É—Å–∫ –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã—Ö –ª–µ–Ω—Ç
                if not self.config.RSS_ACTIVE[i]:
                    logger.debug("‚è≠ –õ–µ–Ω—Ç–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∞: %s", url)
                    continue

                # –î–≤–æ–π–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Å—Å–∏–∏
                if self.rss_parser.session.closed:
                    await self._recreate_session()
                    
                logger.debug("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –ª–µ–Ω—Ç—ã: %s", url)
                start_time = time.time()
                feed_content = await self.rss_parser.fetch_feed(url)
                
                if not feed_content:
                    logger.info("üö´ –õ–µ–Ω—Ç–∞ –ø—É—Å—Ç–∞: %s", url)
                    continue
                    
                # –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–ø–∏—Å–µ–π
                entries = self.rss_parser.parse_entries(feed_content)
                if not entries:
                    logger.info("üîç –ù–µ—Ç –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π –≤ –ª–µ–Ω—Ç–µ: %s", url)
                    continue
                    
                # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
                valid_entries = []
                for entry in entries:
                    if isinstance(entry, dict) and entry.get('link'):
                        valid_entries.append(entry)
                    elif isinstance(entry, str) and entry.strip():
                        valid_entries.append({'link': entry, 'source': url})
                
                if not valid_entries:
                    logger.info("üîç –ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –≤ –ª–µ–Ω—Ç–µ: %s", url)
                    continue
                    
                new_posts.extend(valid_entries)
                active_feeds += 1
                elapsed = time.time() - start_time
                logger.info("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ %d –∑–∞–ø–∏—Å–µ–π –∏–∑ %s (%.2f —Å–µ–∫)", 
                            len(valid_entries), urlparse(url).netloc, elapsed)
                    
            except Exception as e:
                logger.error("‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ª–µ–Ω—Ç—ã %s: %s", url, str(e))
                self.stats['errors'] += 1
                
        total_new = len(new_posts)
        if total_new == 0:
            logger.info("üîç –í—Å–µ –ª–µ–Ω—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã, –Ω–æ–≤—ã—Ö –ø–æ—Å—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        else:
            logger.info("üì• –í—Å–µ–≥–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ %d –Ω–æ–≤—ã—Ö –ø–æ—Å—Ç–æ–≤ –∏–∑ %d –ª–µ–Ω—Ç", total_new, active_feeds)
        
        return new_posts
    
    def _load_publication_settings(self, config):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞"""
        try:
            # –†–µ–∂–∏–º –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ (delay/schedule)
            self.publication_mode = os.getenv('PUBLICATION_MODE', 'delay').lower()
            if self.publication_mode not in ['delay', 'schedule']:
                self.publication_mode = 'delay'
                logger.warning("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π PUBLICATION_MODE, —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Ä–µ–∂–∏–º 'delay'")

            # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –ø–æ—Å—Ç–∞–º–∏ (—Å–µ–∫)
            self.min_delay = int(os.getenv('MIN_DELAY_BETWEEN_POSTS', 300))
            
            # –ß–∞—Å—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ (–¥–ª—è —Ä–µ–∂–∏–º–∞ schedule)
            schedule_hours = os.getenv('PUBLICATION_SCHEDULE_HOURS', '9,12,18')
            self.publication_schedule = sorted(list({int(h) for h in schedule_hours.split(',') if h.isdigit() and 0 <= int(h) <= 23}))
            if not self.publication_schedule:
                self.publication_schedule = [9, 12, 18]
                logger.warning("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ PUBLICATION_SCHEDULE_HOURS, —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ 9,12,18")

            # –í—Ä–µ–º—è —Å–ª–µ–¥—É—é—â–µ–π –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ (–≤—ã—á–∏—Å–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
            self.next_scheduled_time = None
            
            logger.info(f"–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: mode={self.publication_mode}, delay={self.min_delay}s, schedule={self.publication_schedule}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: {str(e)}")
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            self.publication_mode = 'delay'
            self.min_delay = 300
            self.publication_schedule = [9, 12, 18]
    
    def save_publication_settings(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤ .env —Ñ–∞–π–ª"""
        try:
            with open('.env', 'r+') as f:
                lines = f.readlines()
                f.seek(0)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∏–ª–∏ –¥–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                updated = False
                new_lines = []
                
                for line in lines:
                    if line.startswith('PUBLICATION_MODE='):
                        new_lines.append(f'PUBLICATION_MODE={self.publication_mode}\n')
                        updated = True
                    elif line.startswith('MIN_DELAY_BETWEEN_POSTS='):
                        new_lines.append(f'MIN_DELAY_BETWEEN_POSTS={self.min_delay}\n')
                        updated = True
                    elif line.startswith('PUBLICATION_SCHEDULE_HOURS='):
                        new_lines.append(f'PUBLICATION_SCHEDULE_HOURS={",".join(map(str, self.publication_schedule))}\n')
                        updated = True
                    else:
                        new_lines.append(line)
                
                # –ï—Å–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–µ –±—ã–ª–æ –≤ —Ñ–∞–π–ª–µ - –¥–æ–±–∞–≤–ª—è–µ–º
                if not updated:
                    new_lines.extend([
                        f'\n# Publication settings\n',
                        f'PUBLICATION_MODE={self.publication_mode}\n',
                        f'MIN_DELAY_BETWEEN_POSTS={self.min_delay}\n',
                        f'PUBLICATION_SCHEDULE_HOURS={",".join(map(str, self.publication_schedule))}\n'
                    ])
                
                f.writelines(new_lines)
                f.truncate()
            
            logger.info("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ .env —Ñ–∞–π–ª")
            return True
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: {str(e)}")
            return False
    
    def get_publication_settings(self) -> dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏"""
        return {
            'mode': self.publication_mode,
            'delay': self.min_delay,
            'schedule': [t.strftime('%H:%M') for t in self.publication_schedule]
        }
    
    async def update_publication_settings(self, mode: str, schedule: list = None, delay: int = None) -> bool:
        if mode not in ['schedule', 'delay']:
            raise ValueError("–ù–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–π —Ä–µ–∂–∏–º –ø—É–±–ª–∏–∫–∞—Ü–∏–∏")
        
        self.publication_mode = mode
        
        try:
            if mode == 'schedule':
                if not schedule:
                    raise ValueError("–î–ª—è —Ä–µ–∂–∏–º–∞ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å schedule")
                
                time_objects = []
                for t in schedule:
                    try:
                        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–∞ –≤—Ä–µ–º–µ–Ω–∏
                        if re.match(r"^\d{1}:\d{2}$", t):
                            t = f"0{t}"  # "9:30" -> "09:30"
                        
                        # –ü–∞—Ä—Å–∏–Ω–≥ –≤ –æ–±—ä–µ–∫—Ç time
                        time_obj = datetime.strptime(t.strip(), '%H:%M').time()
                        time_objects.append(time_obj)
                    except ValueError:
                        logger.warning(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ –Ω–µ–≤–∞–ª–∏–¥–Ω–æ–µ –≤—Ä–µ–º—è: {t}")
                        continue
                
                self.publication_schedule = sorted(time_objects)
                self._calculate_next_scheduled_time()  # –ü–µ—Ä–µ—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏
            else:
                if delay is None:
                    raise ValueError("–î–ª—è —Ä–µ–∂–∏–º–∞ –∑–∞–¥–µ—Ä–∂–∫–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å delay")
                self.min_delay = delay
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∫–æ–Ω—Ñ–∏–≥
            self.config.PUBLICATION_MODE = mode
            self.config.MIN_DELAY_BETWEEN_POSTS = self.min_delay
            
            if mode == 'schedule':
                schedule_str = ','.join([t.strftime('%H:%M') for t in self.publication_schedule])
                self.config.PUBLICATION_SCHEDULE = schedule_str
                self.config.save_to_env_file("PUBLICATION_SCHEDULE", schedule_str)
            
            self.config.save_to_env_file("PUBLICATION_MODE", mode)
            self.config.save_to_env_file("MIN_DELAY_BETWEEN_POSTS", str(self.min_delay))
            
            logger.info(f"–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –æ–±–Ω–æ–≤–ª–µ–Ω—ã: mode={mode}, delay={self.min_delay}, schedule={[t.strftime('%H:%M') for t in self.publication_schedule]}")
            return True
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: {str(e)}", exc_info=True)
            raise

    def set_publication_mode(self, mode: str, **params) -> None:
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–µ–∂–∏–º–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤ .env"""
        valid_modes = ['delay', 'schedule']
        if mode not in valid_modes:
            raise ValueError(f"–ù–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–π —Ä–µ–∂–∏–º. –î–æ–ø—É—Å—Ç–∏–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: {valid_modes}")
        
        # –û—Å–Ω–æ–≤–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–µ–∂–∏–º–∞
        self.publication_mode = mode
        logger.info(f"–†–µ–∂–∏–º –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –∏–∑–º–µ–Ω–µ–Ω –Ω–∞ '{mode}'")
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤
        if mode == 'delay':
            if 'delay_seconds' in params:
                self.min_delay = params['delay_seconds']
        elif mode == 'schedule':
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω—ã –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            if 'schedule_hours' in params:
                raw_hours = params['schedule_hours']
                processed_hours = {int(h) for h in raw_hours if 0 <= int(h) <= 23}
                self.publication_schedule = sorted(processed_hours)
                
                # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –µ—Å–ª–∏ –ø—É—Å—Ç–æ
                if not self.publication_schedule:
                    self.publication_schedule = [9, 12, 18]
            
            # –ü–µ—Ä–µ—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
            self._calculate_next_scheduled_time()
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        self.save_publication_settings()
        logger.info(
            f"–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Ä–µ–∂–∏–º –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: {self.publication_mode} "
            f"(delay={self.min_delay}, schedule={self.publication_schedule})"
        )
        
    async def _wait_for_publication_time(self):
        """–û–∂–∏–¥–∞–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ —Å —Ç–æ—á–Ω–æ—Å—Ç—å—é –¥–æ —Å–µ–∫—É–Ω–¥"""
        if self.publication_mode != 'schedule' or not self.next_scheduled_time:
            return
            
        tz = pytz.timezone(self.config.TIMEZONE)
        now = datetime.now(tz)
        
        # –ï—Å–ª–∏ –≤—Ä–µ–º—è —É–∂–µ –Ω–∞—Å—Ç—É–ø–∏–ª–æ - –≤—ã—Ö–æ–¥–∏–º
        if now >= self.next_scheduled_time:
            logger.debug("–í—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ —É–∂–µ –Ω–∞—Å—Ç—É–ø–∏–ª–æ")
            return
            
        # –°–∫–æ–ª—å–∫–æ –æ—Å—Ç–∞–ª–æ—Å—å –∂–¥–∞—Ç—å
        wait_seconds = (self.next_scheduled_time - now).total_seconds()
        
        # –ï—Å–ª–∏ –æ—Å—Ç–∞–ª–æ—Å—å –º–µ–Ω–µ–µ 1 —Å–µ–∫—É–Ω–¥—ã - –≤—ã—Ö–æ–¥–∏–º
        if wait_seconds <= 1:
            return
            
        logger.info(f"–û–∂–∏–¥–∞–Ω–∏–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: {wait_seconds:.1f} —Å–µ–∫ ({wait_seconds/60:.1f} –º–∏–Ω)")
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –æ–∂–∏–¥–∞–Ω–∏–µ –Ω–∞ –∫–æ—Ä–æ—Ç–∫–∏–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
        start_wait = time.time()
        last_log = time.time()
        
        while wait_seconds > 1 and self.is_running:  # –û—Å—Ç–∞–≤–ª—è–µ–º –∑–∞–ø–∞—Å –≤ 1 —Å–µ–∫—É–Ω–¥—É
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–µ 1 —Å–µ–∫—É–Ω–¥—É –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
            chunk = min(wait_seconds, 1.0)
            await asyncio.sleep(chunk)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–µ–µ—Å—è –≤—Ä–µ–º—è
            now = datetime.now(tz)
            wait_seconds = (self.next_scheduled_time - now).total_seconds()
            
            # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥
            if time.time() - last_log > 30:
                logger.info(f"–û—Å—Ç–∞–ª–æ—Å—å –∂–¥–∞—Ç—å: {wait_seconds:.1f} —Å–µ–∫")
                last_log = time.time()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–ª–∞–≥ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è
            if self.schedule_changed.is_set():
                logger.info("–†–∞—Å–ø–∏—Å–∞–Ω–∏–µ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å, –ø—Ä–µ—Ä—ã–≤–∞—é –æ–∂–∏–¥–∞–Ω–∏–µ")
                self.schedule_changed.clear()
                return
        
    async def _process_new_posts(self, posts: List[Dict]):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–≤—ã—Ö –ø–æ—Å—Ç–æ–≤ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        if not posts:
            logger.info("üîç –ù–µ—Ç –Ω–æ–≤—ã—Ö –ø–æ—Å—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return
            
        # –£–±—Ä–∞—Ç—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º—ã—Ö –ø–æ—Å—Ç–æ–≤
        max_to_process = len(posts)  # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –í–°–ï –ø–æ—Å—Ç—ã
        
        duplicate_count = 0
        processed_count = 0
        skipped_count = 0
        start_time = time.time()
        
        logger.info(f"üîÑ –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {max_to_process} –Ω–æ–≤—ã—Ö –ø–æ—Å—Ç–æ–≤")
        
        # –í—Ä–µ–º–µ–Ω–Ω—ã–π –∫–µ—à –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        duplicate_cache = set()
        
        for i, post in enumerate(posts[:max_to_process]):
            if not self.is_running:
                break
                
            try:
                # –ë—ã—Å—Ç—Ä–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
                temp_post = self._quick_normalize(post)
                if not temp_post:
                    skipped_count += 1
                    continue
                    
                # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è ID
                post_id = self._generate_post_id(temp_post)
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–∞
                if self.state_manager.is_entry_sent(post_id):
                    duplicate_count += 1
                    duplicate_cache.add(post_id)
                    continue
                    
                # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –ø–æ—Å—Ç–∞–º–∏
                await self._enforce_post_delay()
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Å—Ç–∞
                if await self._process_single_post(post):
                    processed_count += 1
                else:
                    skipped_count += 1
                    
            except Exception as e:
                logger.error("‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ—Å—Ç–∞: %s", str(e))
                skipped_count += 1
        
        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        elapsed = time.time() - start_time
        total_skipped = duplicate_count + skipped_count
        
        logger.info("üìä –ò—Ç–æ–≥–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ (%.2f —Å–µ–∫):", elapsed)
        logger.info("   ‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: %d", processed_count)
        logger.info("   ‚è≠ –ü—Ä–æ–ø—É—â–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: %d", duplicate_count)
        
        if skipped_count > 0:
            logger.info("   ‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ –ø–æ –¥—Ä—É–≥–∏–º –ø—Ä–∏—á–∏–Ω–∞–º: %d", skipped_count)
        
        logger.info("   üîÑ –í—Å–µ–≥–æ –ø—Ä–æ–ø—É—â–µ–Ω–æ: %d", total_skipped)
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        self.stats['duplicates_rejected'] += duplicate_count
        self.stats['posts_processed'] = self.stats.get('posts_processed', 0) + processed_count
        self.stats['posts_skipped'] = self.stats.get('posts_skipped', 0) + total_skipped

    def _quick_normalize(self, post: Union[Dict, str]) -> Optional[Dict]:
        """–ë—ã—Å—Ç—Ä–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ–ª—å–∫–æ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
        if isinstance(post, dict) and post.get('link'):
            return {
                'link': post['link'],
                'title': post.get('title', '')
            }
        elif isinstance(post, str) and post:
            return {'link': post, 'title': ''}
        return None

    async def _enforce_post_delay(self):
        """–û–±–µ—Å–ø–µ—á–µ–Ω–∏–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –∑–∞–¥–µ—Ä–∂–∫–∏ –º–µ–∂–¥—É –ø–æ—Å—Ç–∞–º–∏"""
        time_since_last = time.time() - self.last_post_time
        if time_since_last < self.config.MIN_DELAY_BETWEEN_POSTS:
            delay = self.config.MIN_DELAY_BETWEEN_POSTS - time_since_last
            logger.debug("Waiting %.1f seconds before next post", delay)
            await asyncio.sleep(delay)

    def _update_processing_stats(self, cycle_time: float):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        self.stats['total_processing_time'] += cycle_time
        self.stats['cycles_completed'] += 1
        self.stats['avg_processing_time'] = (
            self.stats['total_processing_time'] / self.stats['cycles_completed']
        )
        self.stats['max_feed_time'] = max(self.stats['max_feed_time'], cycle_time)
        self.stats['min_feed_time'] = min(self.stats['min_feed_time'], cycle_time)

    async def _process_single_post(self, post: Union[Dict, str]) -> bool:
        success = False
        image_path = None
        normalized_post = None
        
        try:
            # 1. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ—Å—Ç–∞
            normalized_post = self._normalize_post(post)
            if not normalized_post:
                logger.debug("–ü–æ—Å—Ç –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω")
                return False

            # 2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è ID
            post_id = self._generate_post_id(normalized_post)
            normalized_post['post_id'] = post_id
            original_title = normalized_post.get('title', '')[:50]
            logger.debug(f"üÜî –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Å—Ç–∞: {original_title}")

            # 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            processed_content = await self._process_post_content(normalized_post)
            if processed_content is None:
                logger.debug("–ö–æ–Ω—Ç–µ–Ω—Ç –ø–æ—Å—Ç–∞ –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω")
                return False

            # 4. –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            if self.config.IMAGE_SOURCE != 'none':
                if normalized_post.get('image_url'):
                    image_path = await self._download_image(
                        normalized_post['image_url'], 
                        normalized_post['post_id']
                    )
                
                if not image_path and normalized_post.get('link'):
                    image_url = await self.rss_parser.extract_primary_image(
                        normalized_post['link']
                    )
                    if image_url:
                        image_path = await self._download_image(
                            image_url, 
                            normalized_post['post_id']
                        )
            
            if not image_path:
                logger.info(f"üö´ –ü—Ä–æ–ø—É—Å–∫ –ø–æ—Å—Ç–∞: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ {original_title}")
                return False

            # 5. –û–ñ–ò–î–ê–ù–ò–ï –¢–û–ß–ù–û–ì–û –í–†–ï–ú–ï–ù–ò –ü–£–ë–õ–ò–ö–ê–¶–ò–ò
            if self.publication_mode == 'schedule':
                # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –≤—Ä–µ–º—è –ø–µ—Ä–µ–¥ –æ–∂–∏–¥–∞–Ω–∏–µ–º
                self._calculate_next_scheduled_time()
                
                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —á–∞—Å–æ–≤–æ–≥–æ –ø–æ—è—Å–∞ –î–û –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
                tz = pytz.timezone(self.config.TIMEZONE)
                now = datetime.now(tz)
                
                if now < self.next_scheduled_time:
                    wait_seconds = (self.next_scheduled_time - now).total_seconds()
                    logger.info(f"–û–∂–∏–¥–∞–Ω–∏–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: {wait_seconds:.1f} —Å–µ–∫ ({wait_seconds/60:.1f} –º–∏–Ω)")
                    
                    # –î–µ–ª–∏–º –æ–∂–∏–¥–∞–Ω–∏–µ –Ω–∞ –Ω–µ–±–æ–ª—å—à–∏–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
                    while wait_seconds > 0 and self.is_running:
                        chunk = min(wait_seconds, 1.0)  # –ú–∞–∫—Å–∏–º—É–º 1 —Å–µ–∫—É–Ω–¥–∞
                        await asyncio.sleep(chunk)
                        
                        # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –æ—Å—Ç–∞–≤—à–µ–µ—Å—è –≤—Ä–µ–º—è
                        now = datetime.now(tz)
                        wait_seconds = (self.next_scheduled_time - now).total_seconds()
                        
                        # –í—ã—Ö–æ–¥–∏–º –µ—Å–ª–∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å
                        if self.schedule_changed.is_set():
                            logger.info("–†–∞—Å–ø–∏—Å–∞–Ω–∏–µ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å, –ø—Ä–µ—Ä—ã–≤–∞—é –æ–∂–∏–¥–∞–Ω–∏–µ")
                            self.schedule_changed.clear()
                            return False
            else:
                await self._enforce_post_delay()

            # 6. –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –Ω–∞—Å—Ç—É–ø–∏–ª–æ
            tz = pytz.timezone(self.config.TIMEZONE)
            now = datetime.now(tz)
            
            if self.publication_mode == 'schedule' and now < self.next_scheduled_time:
                logger.warning("–í—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –µ—â–µ –Ω–µ –Ω–∞—Å—Ç—É–ø–∏–ª–æ, –ø—Ä–æ–ø—É—Å–∫ –æ—Ç–ø—Ä–∞–≤–∫–∏")
                return False

            # 7. –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ Telegram
            processed_title = processed_content.get('title', '')[:50]
            success = await self._send_post_to_telegram(
                processed_content, 
                normalized_post, 
                image_path
            )
            
            if success:
                self._update_stats_after_post(normalized_post)
                logger.info(f"‚úÖ –ü–æ—Å—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω: {processed_title}")
            
        except Exception as e:
            logger.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}", exc_info=True)
            
        finally:
            if image_path and os.path.exists(image_path):
                try:
                    os.unlink(image_path)
                    logger.debug(f"–í—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —É–¥–∞–ª–µ–Ω: {image_path}")
                except OSError as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}")
        
        return success

    def _generate_content_hash(self, post: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è MD5 —Ö–µ—à–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –ø–æ—Å—Ç–∞"""
        content = f"{post.get('title', '')}{post.get('description', '')}"
        return hashlib.md5(content.encode('utf-8')).hexdigest()

    def _normalize_post(self, post: Union[Dict, str]) -> Dict:
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ—Å—Ç–∞ –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç"""
        if isinstance(post, str):
            return {
                'link': post,
                'title': '',
                'description': '',
                'pub_date': datetime.now().isoformat()
            }
        if isinstance(post, dict):
            # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–æ–ª—è –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç
            post.setdefault('link', '')
            post.setdefault('title', '')
            post.setdefault('description', '')
            post.setdefault('pub_date', datetime.now().isoformat())
            return post
        logger.error("–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø –ø–æ—Å—Ç–∞: %s", type(post))
        return None

    def _normalize_image_url(self, url: str, base_url: str) -> str:
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
        if not url:
            return ""
        
        # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—É—Ç–µ–π
        if url.startswith('//'):
            return f'https:{url}'
        if url.startswith('/'):
            parsed_base = urlparse(base_url)
            return f"{parsed_base.scheme}://{parsed_base.netloc}{url}"
        
        # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞
        if url.startswith('http:/') and not url.startswith('http://'):
            url = url.replace('http:/', 'http://')
        if url.startswith('https:/') and not url.startswith('https://'):
            url = url.replace('https:/', 'https://')
        
        return url

    def _generate_post_id(self, post: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ ID –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        stable_data = f"{post.get('link', '')}{post.get('title', '')}"
        return hashlib.md5(stable_data.encode()).hexdigest()

    def _update_stats_after_post(self, post: Dict):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –æ—Ç–ø—Ä–∞–≤–∫–∏"""
        self.state_manager.add_sent_entry(post)
        self.stats['posts_sent'] += 1
        self.stats['last_post'] = datetime.now()
        self.last_post_time = time.time()
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ—á–∞—Å–æ–≤–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        hour = datetime.now().hour
        self.hourly_stats[f"hour_{hour}"] = self.hourly_stats.get(f"hour_{hour}", 0) + 1
        logger.debug("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞: +1 –ø–æ—Å—Ç")

    def _should_skip_post(self, post: Dict) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç –±–µ–∑ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        post_id = post.get('post_id', '')
        if not post_id:
            return True
            
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–∞ –ø–æ ID
        if self.state_manager.is_entry_sent(post_id):
            return True
            
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–∞ –ø–æ —Ö–µ—à—É –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        content_hash = self._generate_content_hash(post)
        if content_hash and self.state_manager.is_hash_sent(content_hash):
            return True
            
        return False
    
    async def _process_post_content(self, post: Dict) -> Optional[Dict[str, str]]:
        try:
            title = post.get('title', '')
            description = post.get('description', '')
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≥–∏–±–∫–∏–µ –ø–æ—Ä–æ–≥–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏
            MIN_TITLE_LEN = 5  # –≤–º–µ—Å—Ç–æ 5
            MIN_DESC_LEN = 0  # –≤–º–µ—Å—Ç–æ 20
            
            if len(title) < MIN_TITLE_LEN or len(description) < MIN_DESC_LEN:
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è —Ç–æ—á–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
                logger.warning(f"–ö–æ—Ä–æ—Ç–∫–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç: title={len(title)}, desc={len(description)}")
                return None

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ª–æ–≤–∏—è –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ò–ò
            use_ai = (
                self.config.ENABLE_YAGPT and
                self.yandex_gpt and
                self.yandex_gpt.active and
                self.yandex_gpt.is_available()
            )

            # –ï—Å–ª–∏ –ò–ò –æ—Ç–∫–ª—é—á–µ–Ω - –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
            if not use_ai:
                return {
                    'title': self._truncate_text(title, self.config.MAX_TITLE_LENGTH),
                    'description': self._truncate_text(description, self.config.MAX_DESC_LENGTH)
                }

            # –í—ã–∑–æ–≤ –ò–ò –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            logger.debug(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—Ä–µ–∑ YandexGPT: {title[:50]}...")
            result = await self.yandex_gpt.enhance(title, description)
            
            # –ï—Å–ª–∏ –ò–ò –≤–µ—Ä–Ω—É–ª None (–ø–ª–æ—Ö–æ–π –æ—Ç–≤–µ—Ç) - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ—Å—Ç
            if result is None:
                logger.warning("–ò–ò –≤–µ—Ä–Ω—É–ª –Ω–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –ø—Ä–æ–ø—É—Å–∫ –ø–æ—Å—Ç–∞")
                return None
                
            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
            processed_content = {
                'title': self._truncate_text(result.get('title', title), self.config.MAX_TITLE_LENGTH),
                'description': self._truncate_text(result.get('description', description), self.config.MAX_DESC_LENGTH)
            }
            
            # –ñ—ë—Å—Ç–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ SEO-–º—É—Å–æ—Ä
            if self._contains_low_quality_phrases(processed_content):
                logger.warning("–û–±–Ω–∞—Ä—É–∂–µ–Ω SEO-–º—É—Å–æ—Ä –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –ò–ò, –ø—Ä–æ–ø—É—Å–∫ –ø–æ—Å—Ç–∞")
                return None
                
            return processed_content

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {str(e)}", exc_info=True)
            return None  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ—Å—Ç –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
        
    def _contains_low_quality_phrases(self, content: Dict) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –∫–æ–Ω—Ç–µ–Ω—Ç SEO-–º—É—Å–æ—Ä"""
        # –ö–ª—é—á–µ–≤—ã–µ —Ñ—Ä–∞–∑—ã –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞
        skip_phrases = [
            "–≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ –µ—Å—Ç—å –º–Ω–æ–≥–æ —Å–∞–π—Ç–æ–≤",
            "–ø–æ—Å–º–æ—Ç—Ä–∏—Ç–µ, —á—Ç–æ –Ω–∞—à–ª–æ—Å—å –≤ –ø–æ–∏—Å–∫–µ",
            "–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã:",
            "—Å–º–æ—Ç—Ä–∏—Ç–µ —Ç–∞–∫–∂–µ:",
            "—á–∏—Ç–∞–π—Ç–µ –¥–∞–ª–µ–µ",
            "—á–∏—Ç–∞–π—Ç–µ —Ç–∞–∫–∂–µ",
            "—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º –ø—Ä–æ—á–∏—Ç–∞—Ç—å",
            "–ø–æ–¥—Ä–æ–±–Ω–µ–µ –Ω–∞ —Å–∞–π—Ç–µ",
            "–¥—Ä—É–≥–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏:",
            "–±–æ–ª—å—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –º–æ–∂–Ω–æ –Ω–∞–π—Ç–∏",
            "–≤ –ø–æ–∏—Å–∫–µ –Ω–∞–π–¥–µ–Ω—ã"
            "—Å–∫–∏–¥–∫–∞"
            "—Å–∫–∏–¥–∫–∏"
            "–∫—É–ø–æ–Ω"
            "–∫—É–ø–æ–Ω—ã"
            "–∞–∫—Ü–∏—è"
            "–∞–∫—Ü–∏–∏"
        ]
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –æ–ø–∏—Å–∞–Ω–∏–µ
        full_text = f"{content['title']} {content['description']}".lower()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∑–∞–ø—Ä–µ—â—ë–Ω–Ω—ã—Ö —Ñ—Ä–∞–∑
        for phrase in skip_phrases:
            if phrase in full_text:
                return True
                
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ Markdown-—Å—Å—ã–ª–∫–∏
        if re.search(r'\[.*\]\(https?://[^\)]+\)', full_text):
            return True
            
        return False

    def _log_skipped_post(self, post: Dict, reason: str):
        """–õ–æ–≥–∏—Ä—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–ø—É—â–µ–Ω–Ω–æ–º –ø–æ—Å—Ç–µ"""
        log_data = {
            'timestamp': datetime.now().isoformat(),
            'original_title': post.get('title'),
            'original_description': post.get('description'),
            'link': post.get('link'),
            'reason': reason,
            'post_id': post.get('post_id', '')
        }
        
        try:
            # –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –ª–æ–≥–æ–≤ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
            os.makedirs('logs', exist_ok=True)
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ JSON Lines —Ñ–æ—Ä–º–∞—Ç
            with open('logs/skipped_posts.json', 'a', encoding='utf-8') as f:
                f.write(json.dumps(log_data, ensure_ascii=False) + '\n')
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–ø—É—â–µ–Ω–Ω–æ–≥–æ –ø–æ—Å—Ç–∞: {str(e)}")

    @staticmethod
    def _truncate_text(text: str, max_length: int) -> str:
        """–û–±—Ä–µ–∑–∞–µ—Ç —Ç–µ–∫—Å—Ç –¥–æ —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–ª–∏–Ω—ã —Å —É—á–µ—Ç–æ–º —Å–ª–æ–≤"""
        if len(text) <= max_length:
            return text
            
        # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø—Ä–æ–±–µ–ª –ø–µ—Ä–µ–¥ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω–æ–π
        truncated = text[:max_length]
        if last_space := truncated.rfind(' '):
            truncated = truncated[:last_space]
            
        return truncated + '...'

    async def _get_post_image(self, post: Dict) -> Optional[str]:
        # –†–µ–∂–∏–º none - –±–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        if self.config.IMAGE_SOURCE == 'none':
            return None

        # –†–µ–∂–∏–º original - –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if self.config.IMAGE_SOURCE == 'original':
            image_url = None
                
            # 1. –ü—Ä–æ–±—É–µ–º –≤–∑—è—Ç—å –∏–∑ RSS
            if post.get('image_url'):
                image_url = post['image_url']
                
            # 2. –ü–∞—Ä—Å–∏–º HTML –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤–Ω—É—Ç—Ä–∏ –Ω–æ–≤–æ—Å—Ç–∏
            if not image_url and post.get('description'):
                image_url = await self._find_image_in_html_content(
                    post['description'], 
                    post.get('link', '')
                )
            # 3. –°–∫–∞—á–∏–≤–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            if image_url:
                return await self._download_image(image_url, post['post_id'])
                
            return None  # –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback!
        
        # –†–µ–∂–∏–º 'template' - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –ª–æ–≥–∏–∫–∞ —Å fallback
        # 1. –ü—Ä—è–º–∞—è —Å—Å—ã–ª–∫–∞ –∏–∑ RSS
        if post.get('image_url'):
            image_path = await self._download_image(post['image_url'], post['post_id'])
            if image_path:
                return image_path
                
        # 2. –ü–æ–∏—Å–∫ –≤ HTML-–∫–æ–Ω—Ç–µ–Ω—Ç–µ
        if post.get('description'):
            image_url = await self._find_image_in_html(post['description'], post.get('link', ''))
            if image_url:
                image_path = await self._download_image(image_url, post['post_id'])
                if image_path:
                    return image_path
                    
        # 3. Fallback - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if self.config.IMAGE_FALLBACK and self.config.ENABLE_IMAGE_GENERATION:
            return await self._generate_image_with_semaphore(post.get('title', ''))
                        
        return None

    async def _find_image_in_html(self, html_content: str, base_url: str) -> Optional[str]:
        """–ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ HTML-–∫–æ–Ω—Ç–µ–Ω—Ç–µ —Å –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Ç–∏–ø–æ–≤"""
        if not html_content:
            return None

        try:
            from bs4 import BeautifulSoup, Tag
            from bs4.element import NavigableString

            soup = BeautifulSoup(html_content, 'html.parser')
            
            # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ OpenGraph/twitter –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            for meta in soup.find_all('meta'):
                if isinstance(meta, Tag):
                    # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –∞—Ç—Ä–∏–±—É—Ç–æ–≤
                    meta_property = meta.attrs.get('property', '') or meta.attrs.get('name', '')
                    if not isinstance(meta_property, str):
                        continue
                        
                    # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
                    meta_property_lower = meta_property.lower() if meta_property else ''
                    if meta_property_lower in {'og:image', 'twitter:image', 'og:image:url'}:
                        image_url = meta.attrs.get('content', '')
                        if isinstance(image_url, str) and image_url.strip():
                            normalized_url = self._normalize_image_url(image_url, base_url)
                            if normalized_url:
                                return normalized_url
            
            # 2. –ü–æ–∏—Å–∫ –ø–æ img —Ç–µ–≥–∞–º
            for img in soup.find_all('img'):
                if isinstance(img, Tag):
                    src = img.attrs.get('src', '')
                    if not isinstance(src, str) or not src.strip():
                        continue
                        
                    # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–ª—É–∂–µ–±–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    src_lower = src.lower() if src else ''
                    if any(bad_word in src_lower for bad_word in ['pixel', 'icon', 'logo', 'spacer', 'ad']):
                        continue
                        
                    normalized_url = self._normalize_image_url(src, base_url)
                    if normalized_url:
                        return normalized_url
            
            return None
            
        except Exception as e:
            logger.debug(f"HTML parsing error: {str(e)}")
            return None

    async def _find_image_in_html_content(self, html_content: str, base_url: str) -> Optional[str]:
        """–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤–Ω—É—Ç—Ä–∏ HTML-–∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        if not html_content:
            return None

        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç–µ–Ω—Ç–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º
            content_images = []
            for img in soup.find_all('img'):
                src = img.get('src', '')
                if not src:
                    continue
                    
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —è–≤–Ω–æ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                if any(bad in src.lower() for bad in ['pixel', 'icon', 'logo', 'spacer', 'ad']):
                    continue
                    
                normalized_url = self._normalize_image_url(src, base_url)
                if not normalized_url:
                    continue
                    
                content_images.append(normalized_url)
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤–æ–µ –ø–æ–¥—Ö–æ–¥—è—â–µ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            return content_images[0] if content_images else None
            
        except Exception as e:
            logger.debug(f"HTML content image search error: {str(e)}")
            return None
    def _normalize_image_url(self, url: str, base_url: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        if not isinstance(url, str):
            return ""
            
        if url.startswith(('http://', 'https://')):
            return url
        if url.startswith('//'):
            return f'https:{url}'
        if url.startswith('/'):
            if not base_url:
                base_url = self.config.RSS_URLS[0] if self.config.RSS_URLS else ""
            parsed = urlparse(base_url)
            return f"{parsed.scheme}://{parsed.netloc}{url}"
        return url

    async def _generate_image_with_semaphore(self, title: str) -> Optional[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å —É—á–µ—Ç–æ–º —Å–µ–º–∞—Ñ–æ—Ä–∞"""
        if not title:
            return None
            
        if self.image_semaphore:
            await self.image_semaphore.acquire()
            try:
                return await self._generate_image(title)
            finally:
                self.image_semaphore.release()
        return await self._generate_image(title)

    async def _generate_image(self, title: str) -> Optional[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ"""
        try:
            logger.debug(f"Generating image for title: {title[:50]}")
            loop = asyncio.get_running_loop()
            
            # –í—ã–Ω–æ—Å–∏–º –æ–ø–µ—Ä–∞—Ü–∏—é –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å
            image_path = await loop.run_in_executor(
                self.image_executor,
                self.image_generator._sync_generate_image,
                title
            )
            
            if image_path:
                self.stats['images_generated'] += 1
                logger.info(f"Image generated: {image_path}")
            return image_path
        except Exception as e:
            logger.error(f"Image generation failed: {str(e)}")
            self.stats['image_errors'] += 1
            return None

    async def _download_image(self, url: str, post_id: str) -> Optional[str]:
        """–ù–∞–¥–µ–∂–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏"""
        if not url or not self.session:
            return None
            
        try:
            # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
            filename = f"{post_id}_{hashlib.md5(url.encode()).hexdigest()[:8]}.jpg"
            temp_path = os.path.join(self.config.OUTPUT_DIR, filename)
            
            async with self.session.get(
                url,
                timeout=aiohttp.ClientTimeout(total=self.config.IMAGE_DOWNLOAD_TIMEOUT)
            ) as response:
                if response.status != 200:
                    logger.debug("Image download failed: HTTP %d", response.status)
                    return None
                    
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
                content_type = response.headers.get('Content-Type', '')
                if not any(x in content_type for x in ['image/jpeg', 'image/png', 'image/webp']):
                    logger.debug("Invalid image content type: %s", content_type)
                    return None
                    
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞
                content_length = int(response.headers.get('Content-Length', 0))
                if content_length < 1024 or content_length > 5 * 1024 * 1024:  # 1KB - 5MB
                    logger.debug("Invalid image size: %d bytes", content_length)
                    return None
                    
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
                async with aiofiles.open(temp_path, 'wb') as f:
                    await f.write(await response.read())
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ Pillow
                try:
                    with Image.open(temp_path) as img:
                        if img.width < self.config.MIN_IMAGE_WIDTH or img.height < self.config.MIN_IMAGE_HEIGHT:
                            raise ValueError(f"Image too small: {img.width}x{img.height}")
                    return temp_path
                except Exception as e:
                    logger.debug("Image validation failed: %s", str(e))
                    os.unlink(temp_path)
                    return None
                    
        except Exception as e:
            logger.debug("Image download error: %s - %s", url, str(e))
            try:
                if 'temp_path' in locals():
                    os.unlink(temp_path)
            except:
                pass
            return None

    def _remove_formatting(self, text: str) -> str:
        """
        –£–¥–∞–ª—è–µ—Ç Markdown, HTML –∏ —Å–ª—É–∂–µ–±–Ω—ã–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞
        :param text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
        :return: –û—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        if not text:
            return ""
        
        # –£–¥–∞–ª–µ–Ω–∏–µ Markdown-—Ä–∞–∑–º–µ—Ç–∫–∏ (**—Ç–µ–∫—Å—Ç**, __—Ç–µ–∫—Å—Ç__)
        text = re.sub(r'\*\*|\_\_', '', text)
        
        # –£–¥–∞–ª–µ–Ω–∏–µ HTML-—Ç–µ–≥–æ–≤
        text = re.sub(r'<[^>]+>', '', text)
        
        # –£–¥–∞–ª–µ–Ω–∏–µ —Å–ª—É–∂–µ–±–Ω—ã—Ö –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤
        text = re.sub(
            r'^(\s*[#\*\s]*(–ó–∞–≥–æ–ª–æ–≤–æ–∫|Title|–ó–∞–≥|–û–ø–∏—Å–∞–Ω–∏–µ|Description|–û–ø—Ü|Desc)[\s:\-\‚Äî]*\s*[#\*\s]*)', 
            '', 
            text, 
            flags=re.IGNORECASE
        )
        
        # –£–¥–∞–ª–µ–Ω–∏–µ –≤–µ–¥—É—â–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
        text = re.sub(r'^[\s\:\-\‚Äî\#\*]+', '', text)
        
        # –£–¥–∞–ª–µ–Ω–∏–µ –¥–≤–æ–π–Ω—ã—Ö –ø—Ä–æ–±–µ–ª–æ–≤
        text = re.sub(r'\s{2,}', ' ', text)
        
        return text.strip()

    async def _send_post_to_telegram(self, content: Dict, post: Dict, image_path: Optional[str]) -> bool:
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –ø–æ—Å—Ç–∞ –≤ Telegram –∫–∞–Ω–∞–ª —Å –æ—á–∏—Å—Ç–∫–æ–π —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        try:
            logger.debug(f"Original title: {content.get('title', '')}")
            logger.debug(f"Original description: {content.get('description', '')}")
            # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ –æ—Ç —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            def clean_text(text: str) -> str:
                """–£–¥–∞–ª—è–µ—Ç Markdown, HTML –∏ —Å–ª—É–∂–µ–±–Ω—ã–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
                if not text:
                    return ""
                
                # –£–¥–∞–ª–µ–Ω–∏–µ Markdown-—Ä–∞–∑–º–µ—Ç–∫–∏ (**—Ç–µ–∫—Å—Ç**, __—Ç–µ–∫—Å—Ç__)
                text = re.sub(r'\*\*|\_\_', '', text)
                
                # –£–¥–∞–ª–µ–Ω–∏–µ HTML-—Ç–µ–≥–æ–≤
                text = re.sub(r'<[^>]+>', '', text)
                
                # –£–¥–∞–ª–µ–Ω–∏–µ —Å–ª—É–∂–µ–±–Ω—ã—Ö –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤ (–ó–∞–≥–æ–ª–æ–≤–æ–∫:, –û–ø–∏—Å–∞–Ω–∏–µ: –∏ —Ç.–¥.)
                text = re.sub(
                    r'^(\s*[#\*\s]*(–ó–∞–≥–æ–ª–æ–≤–æ–∫|Title|–ó–∞–≥|–û–ø–∏—Å–∞–Ω–∏–µ|Description|–û–ø—Ü|Desc)[\s:\-\‚Äî]*\s*[#\*\s]*)', 
                    '', 
                    text, 
                    flags=re.IGNORECASE
                )
                
                # –£–¥–∞–ª–µ–Ω–∏–µ –≤–µ–¥—É—â–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
                text = re.sub(r'^[\s\:\-\‚Äî\#\*]+', '', text)
                
                # –£–¥–∞–ª–µ–Ω–∏–µ –¥–≤–æ–π–Ω—ã—Ö –ø—Ä–æ–±–µ–ª–æ–≤
                text = re.sub(r'\s{2,}', ' ', text)
                
                return text.strip()

            # –û—á–∏—â–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –æ–ø–∏—Å–∞–Ω–∏–µ
            title = clean_text(content.get('title', ''))
            description = clean_text(content.get('description', ''))
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            message_text = f"<b>{title}</b>\n\n{description}\n\n<a href='{post.get('link', '')}'>–ß–∏—Ç–∞—Ç—å –¥–∞–ª–µ–µ</a>"
            logger.debug(f"Cleaned title: {title}")
            logger.debug(f"Cleaned description: {description}")
            # –û—Ç–ø—Ä–∞–≤–∫–∞ –ø–æ—Å—Ç–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –∏–ª–∏ –±–µ–∑
            if image_path and os.path.exists(image_path):
                success = await self.telegram_bot.send_post(
                    title=title,
                    description=description,
                    link=post.get('link', ''),
                    image_path=image_path
                )
            else:
                success = await self.telegram_bot.send_post(
                    title=title,
                    description=description,
                    link=post.get('link', ''),
                    image_path=None
                )
                
            if success:
                logger.info(f"Post sent successfully: {title[:50]}...")
                return True
            else:
                logger.error(f"Failed to send post: {title[:50]}...")
                return False
                
        except Exception as e:
            logger.error(f"Error sending post to Telegram: {str(e)}")
            return False

    def _update_stats_after_post(self, post: Dict):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –æ—Ç–ø—Ä–∞–≤–∫–∏"""
        self.state_manager.add_sent_entry(post)
        self.stats['posts_sent'] += 1
        self.stats['last_post'] = datetime.now()
        self.last_post_time = time.time()
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ—á–∞—Å–æ–≤–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        hour = datetime.now().hour
        self.hourly_stats[f"hour_{hour}"] = self.hourly_stats.get(f"hour_{hour}", 0) + 1
        logger.debug("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞: +1 –ø–æ—Å—Ç")
        
        # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–ª–µ–¥—É—é—â–µ–µ –≤—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –¢–û–õ–¨–ö–û –ï–°–õ–ò –†–ï–ñ–ò–ú –†–ê–°–ü–ò–°–ê–ù–ò–Ø
        if self.publication_mode == 'schedule':
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–µ–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ
            current_schedule = self.publication_schedule.copy()
            
            # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º
            self._calculate_next_scheduled_time()
            
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ
            self.publication_schedule = current_schedule

    async def _cleanup_loop(self):
        """–†–µ–≥—É–ª—è—Ä–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        logger.info("Starting cleanup loop")
        
        while self.is_running:
            try:
                await asyncio.sleep(12 * 3600)  # 12 —á–∞—Å–æ–≤
                
                logger.debug("Running cleanup cycle")
                deleted, freed = await self.image_generator.cleanup_old_images(24)
                
                self.stats['images_deleted'] += deleted
                self.stats['storage_freed'] += freed
                self.stats['last_cleanup'] = datetime.now()
                self.stats['last_cleanup_result'] = f"Deleted {deleted} files, freed {freed:.2f} MB"
                
                logger.info("Cleanup completed: %d files deleted, %.2f MB freed", deleted, freed)
                
            except asyncio.CancelledError:
                logger.info("Cleanup loop cancelled")
                break
            except Exception as e:
                logger.error("Cleanup error: %s", str(e), exc_info=True)

    @property
    def state(self) -> StateManager:
        return self.state_manager
        
    def get_status_text(self) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —Å—Ç–∞—Ç—É—Å–∞ –¥–ª—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞"""
        status = "üü¢ –†–∞–±–æ—Ç–∞–µ—Ç" if self.is_running else "üî¥ –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω"
        last_check = self.stats['last_check'].strftime("%Y-%m-%d %H:%M:%S") if self.stats.get('last_check') else "–Ω–∏–∫–æ–≥–¥–∞"
        last_post = self.stats['last_post'].strftime("%Y-%m-%d %H:%M:%S") if self.stats.get('last_post') else "–Ω–∏–∫–æ–≥–¥–∞"
        
        return (
            "üìä <b>–°—Ç–∞—Ç—É—Å –±–æ—Ç–∞</b>\n\n"
            f"<b>–°–æ—Å—Ç–æ—è–Ω–∏–µ:</b> {status}\n"
            f"<b>–ü–æ—Å–ª–µ–¥–Ω—è—è –ø—Ä–æ–≤–µ—Ä–∫–∞ RSS:</b> {last_check}\n"
            f"<b>–ü–æ—Å–ª–µ–¥–Ω–∏–π –ø–æ—Å—Ç:</b> {last_post}\n"
            f"<b>–û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –ø–æ—Å—Ç–æ–≤:</b> {self.stats.get('posts_sent', 0)}\n"
            f"<b>–û—à–∏–±–æ–∫:</b> {self.stats.get('errors', 0)}\n"
            f"<b>–î—É–±–ª–∏–∫–∞—Ç–æ–≤ –æ—Ç–∫–ª–æ–Ω–µ–Ω–æ:</b> {self.stats.get('duplicates_rejected', 0)}\n"
            f"<b>–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–π YandexGPT:</b> {self.stats.get('yagpt_used', 0)}\n"
            f"<b>–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:</b> {self.stats.get('images_generated', 0)}\n"
            f"<b>–õ–µ–Ω—Ç –≤ –æ–±—Ä–∞–±–æ—Ç–∫–µ:</b> {len(self.config.RSS_URLS)}"
        )
    
    async def toggle_rss_feed(self, index: int, enable: bool) -> bool:
        """–ê–∫—Ç–∏–≤–∏—Ä—É–µ—Ç/–¥–µ–∞–∫—Ç–∏–≤–∏—Ä—É–µ—Ç RSS-–ª–µ–Ω—Ç—É"""
        try:
            if 0 <= index < len(self.config.RSS_URLS):
                self.config.RSS_ACTIVE[index] = enable
                self.config.save_to_env_file("RSS_ACTIVE", str(self.config.RSS_ACTIVE))
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ä—Å–µ—Ä
                self.rss_parser.set_feed_status(
                    self.config.RSS_URLS[index], 
                    enable
                )
                return True
            return False
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –ª–µ–Ω—Ç—ã: {str(e)}")
            return False
            
    def update_rss_state(self, urls: List[str], active: List[bool]):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ RSS –ª–µ–Ω—Ç"""
        self.config.RSS_URLS = urls
        self.config.RSS_ACTIVE = active
        self.config.save_to_env_file("RSS_URLS", json.dumps(urls))
        self.config.save_to_env_file("RSS_ACTIVE", json.dumps(active))
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å—ã –≤ –ø–∞—Ä—Å–µ—Ä–µ
        for i, url in enumerate(urls):
            self.rss_parser.set_feed_status(url, active[i])
    
    def get_rss_state(self) -> Tuple[List[str], List[bool]]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ RSS"""
        
        return self.config.RSS_URLS, self.config.RSS_ACTIVE
    
    async def refresh_rss_status(self) -> bool:
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ RSS –ª–µ–Ω—Ç. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –µ—Å–ª–∏ –±—ã–ª–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è"""
        changed = False
        
        # –ï—Å–ª–∏ —É –ø–∞—Ä—Å–µ—Ä–∞ –µ—Å—Ç—å –º–µ—Ç–æ–¥ refresh_status
        if hasattr(self.rss_parser, 'refresh_status'):
            for url in self.config.RSS_URLS:
                if self.rss_parser.refresh_status(url):
                    changed = True
        
        # –ï—Å–ª–∏ —É –ø–∞—Ä—Å–µ—Ä–∞ –µ—Å—Ç—å –º–µ—Ç–æ–¥ get_last_check
        if hasattr(self.rss_parser, 'get_last_check'):
            for url in self.config.RSS_URLS:
                last_check = self.rss_parser.get_last_check(url)
                if last_check:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª–æ –ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å –º–æ–º–µ–Ω—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
                    if not self.stats.get(f'last_rss_check_{url}') or last_check > self.stats[f'last_rss_check_{url}']:
                        self.stats[f'last_rss_check_{url}'] = last_check
                        changed = True
        
        return changed
    
    def get_rss_status(self) -> List[Dict]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å —Å —É—á–µ—Ç–æ–º –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"""
        status_list = []
        
        for i, url in enumerate(self.config.RSS_URLS):
            status = {
                'url': url,
                'active': self.config.RSS_ACTIVE[i],
                'error_count': 0,
                'last_check': None
            }
            
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫
            if hasattr(self.rss_parser, 'get_error_count'):
                status['error_count'] = self.rss_parser.get_error_count(url)
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
            if hasattr(self.rss_parser, 'get_last_check'):
                status['last_check'] = self.rss_parser.get_last_check(url)
            
            status_list.append(status)
        
        return status_list
            
    async def show_ai_settings(self, callback: CallbackQuery) -> None:
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ AI (–ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª—è–µ–º –≤ Telegram –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å)"""
        # –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ —Ç–µ–ø–µ—Ä—å –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω –≤ Telegram –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ
        pass